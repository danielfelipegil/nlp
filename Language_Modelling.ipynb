{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hangman Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Hangman_(game)\">Hangman game</a> is a simple game whereby one person thinks of a word, which they keep secret from their opponent, who tries to guess the word one character at a time. The game ends when the opponent makes more than a fixed number of incorrect guesses, or they figure out the secret word before then (in which case they *win*). \n",
    "\n",
    "Here's a simple version of the game, and a method allowing interactive play. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowing better python 2 & python 3 compatibility \n",
    "from __future__ import print_function \n",
    "\n",
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of allowed mistakes\n",
    "        verbose: be chatty vs silent\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print(\"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word))\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print(\"You have\", (max_mistakes-mistakes), \"attempts remaining.\")\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print('Guess is', guess)\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print('Already guessed this before.')\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print('Good guess:', ' '.join(mask))\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Sorry, try again.')\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print('Congratulations, you won.')\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print('Out of guesses. The word was', secret_word)    \n",
    "    return mistakes\n",
    "\n",
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    simple function for manual play\n",
    "    \"\"\"\n",
    "    print('Enter your guess:')\n",
    "    try:\n",
    "        return raw_input().lower().strip() # python 3\n",
    "    except NameError:\n",
    "        return input().lower().strip() # python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play the game interactively using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hangman('whatever', human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the words occurring in the *Brown* corpus for *training* an artificial intelligence guessing algorithm, and for *evaluating* the quality of the method. Note that the AI will need to cope with test words that it has not seen before, hence it will need to learn generalisable patterns of characters to make reasonable predictions.\n",
    "\n",
    "The first task is to compute the unique word types occurring in the *Brown* corpus, using `nltk.corpus.Brown`, selecting only words that are entirely comprised of alphabetic characters, and lowercasing the words. Finally, randomly shuffle (`numpy.random.shuffle`) this collection of word types, and split them into disjoint training and testing sets. The test set will contain 1000 word types, and the rest should be in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "39234\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import re\n",
    "# get unique word types ocurring in the Brown corpus selecting only words with alpahbetic characters - lowercase\n",
    "brown_words = set([word.lower() for word in brown.words()])\n",
    "words=list(set([word.lower() for word in brown_words if re.match(r'^[a-z]+$',word)]))\n",
    "# split for training and testing sets\n",
    "np.random.shuffle(words)\n",
    "test_set=words[0:1000]\n",
    "train_set=words[1000:len(words)]\n",
    "print(len(test_set))\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first *AI* attempt will be a trivial random method. For this I will implement a guessing method, similar to the `human` method above, i.e., using the same input arguments and returning a character. It randomly choose a character from the range `'a'...'z'` after excluding the characters that have already been guessed in the current game.\n",
    "\n",
    "To measure the performance I will implement a method that measures the average number of mistakes made by this technique over all the words in the `test_set`. To turn off the printouts for this, we use the `verbose=False` option, and increase the cap on the game length to `max_mistakes=26` and get the average number of mistakes for the random AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing method using the same input arguments as <human> method and returning a character\n",
    "from string import ascii_lowercase\n",
    "\n",
    "def trivial_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed] #Â from all letters in alphabet\n",
    "    return np.random.choice(letter_available)\n",
    "            \n",
    "def evaluate_model(guesser,dataset,**guesser_args):\n",
    "    verbose=False\n",
    "    max_mistakes=26\n",
    "    mistakes=0\n",
    "    for word_test in dataset:   \n",
    "        mistakes+=hangman(word_test, guesser, max_mistakes, verbose,**guesser_args)\n",
    "      \n",
    "    avg_mistakes=mistakes/len(dataset)\n",
    "    return avg_mistakes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.659\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(trivial_guesser,test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first real AI, I will train a *unigram* model over the training set.  This requires  to find the frequencies of characters over all training words. Using this model, I will have a guess function that returns the character with the highest probability, after aggregating (summing) the probability of each blank character in the secret word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequencies of characters over all training words\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_unigram_counts(words):\n",
    "    unigram_counts = Counter()\n",
    "    \n",
    "    # collect initial unigram statistics\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "                unigram_counts[letter] += 1\n",
    "\n",
    "                \n",
    "    return unigram_counts\n",
    "\n",
    "\n",
    "unigram_counts=get_unigram_counts(train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Unigram model we need to calculate the probabilites for every character $c_i$:<br/>\n",
    "\n",
    "$P_{unigram}(c_i)=\\frac{count(c_i)}{M}$<br/>\n",
    "where $M$ is the total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.719\n"
     ]
    }
   ],
   "source": [
    "def unigram_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed]\n",
    "    total_counts = float(sum(unigram_counts.values()))\n",
    "    unigram_probs={}\n",
    "    vocab_size = len(unigram_counts)\n",
    "    # calculate the probability for all letter available\n",
    "    for letter in letter_available:\n",
    "        unigram_probs[letter]=(unigram_counts[letter]+1)/(total_counts+vocab_size) #laplace smoothing\n",
    "    \n",
    "    # get the max probability \n",
    "    letter_choice=max(unigram_probs, key=unigram_probs.get)\n",
    "    return letter_choice\n",
    "\n",
    "        \n",
    "# print the average number of mistakes the unigram method makes over the test set.\n",
    "print(evaluate_model(unigram_guesser,test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the secret word is an important clue that we might exploit. Different length words tend to have different distributions over characters, e.g., short words are less likely to have suffixes or prefixes. We can incorporate this idea by conditioning the unigram model on the length of the secret word, i.e., having *different* unigram models for each length of word (Being careful of an unlikely situation that we encounter a word length that you didn't see in training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Unigram model conditioned we need to calculate the probabilites for every character $c_i$:<br/>\n",
    "\n",
    "$P_{unigram}(c_i|n)=\\frac{count(c_i,n)}{M}$<br/>\n",
    "where $M$ is the total number of characters and $n$ is a fixed lenght for a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement conditioning unigram model on the lengh of the word - different models according the lenght\n",
    "#Â be careful with unseen lenghts in training\n",
    "# create guessing function using the new model and print performance\n",
    "def get_conditional_unigram_counts(words):    \n",
    "    unigram_lenght_counts=defaultdict(Counter)\n",
    "    total_counts=0.0\n",
    "    \n",
    "    # collect initial unigram statistics\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            unigram_lenght_counts[len(word)][letter] += 1\n",
    "            \n",
    "                \n",
    "    return unigram_lenght_counts\n",
    "\n",
    "unigram_lenght_counts=get_conditional_unigram_counts(train_set)\n",
    "\n",
    "def unigram_conditional_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed]\n",
    "    total_counts = float(sum(unigram_lenght_counts[len(mask)].values()))\n",
    "    unigram_probs={}\n",
    "    vocab_size = len(unigram_lenght_counts)\n",
    "    # calculate the probability for all letter available\n",
    "    for letter in letter_available:\n",
    "        # if the word len is not in the training set total_counts=0. \n",
    "        if (total_counts!=0):\n",
    "            unigram_probs[letter]=(unigram_lenght_counts[len(mask)][letter]+1)/(total_counts+vocab_size)\n",
    "        else:\n",
    "            # out-of-vocabulary words = 1 / |V|\n",
    "            vocab_size = len(unigram_lenght_counts)\n",
    "            zerogram_prob = (1 / float(vocab_size)) \n",
    "            unigram_probs[letter]=zerogram_prob \n",
    "            \n",
    "            \n",
    "    # get the max probability \n",
    "    letter_choice=max(unigram_probs, key=unigram_probs.get)\n",
    "    return letter_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.735\n"
     ]
    }
   ],
   "source": [
    "# print the average number of mistakes the unigram method makes oert the test set.\n",
    "print(evaluate_model(unigram_conditional_guesser,test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will be using a *ngram* language model over characters. The order of characters is obviously important, yet this wasn't incorporated in any of the above models. Knowing that the word has the sequence `n _ s s` is a pretty strong clue that the missing character might be `e`. Similarly the distribution over characters that start or end a word are highly biased (e.g., toward common prefixes and suffixes, like *un-*, *-ed* and *-ly*).\n",
    "For this model, I use linear interpolation to smooth between the higher order and lower order models.\n",
    "\n",
    "I will apply the language model to each blank position in the secret word by using as much of the left context as is known. E.g., in `_ e c _ e _ _` we know the full left context for the first blank (context=start of word), we have a context of two characters for the second blank (context=ec), one character for the second last blank (context=e), and no known context for the last one. If we were using a *n=3* order model, we would be able to apply it to the first and second blanks, but would only be able to use the bigram or unigram distributions for the subsequent blanks. As with the unigram model, I sum over the probability distributions for each blank to find the expected count for each character type and select the character with the highest expected count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convert_word(word,n):\n",
    "    start=[]\n",
    "    end=[]\n",
    "    start_index=1\n",
    "    \n",
    "    # padding with sentinent symbols\n",
    "        \n",
    "    while start_index<n:\n",
    "        start.append(\"<s\"+str(start_index)+\">\")\n",
    "        start_index+=1\n",
    "    \n",
    "    end_index=n\n",
    "    while end_index>1:\n",
    "        end.append(\"</s\"+str(end_index-1)+\">\")\n",
    "        end_index-=1\n",
    "    \n",
    "    return start + [l.lower() for l in word] + end\n",
    "\n",
    "def get_ngram_counts(words,n):\n",
    "    ngram_counts = defaultdict(Counter)\n",
    "    \n",
    "    # collect bigram counts\n",
    "    for word in words:\n",
    "        word = convert_word(word,n)\n",
    "        if (n<=len(word)):\n",
    "            n_grams=[word[i:i+n] for i in range(len(word)-(n-1))]\n",
    "            for n_gram in n_grams:\n",
    "                if (n==2):\n",
    "                    ngram_counts[n_gram[0]][n_gram[1]]+=1\n",
    "                elif (n==3):\n",
    "                    ngram_counts[(n_gram[0],n_gram[1])][n_gram[2]]+=1\n",
    "                elif (n==4):\n",
    "                    ngram_counts[(n_gram[0],n_gram[1],n_gram[2])][n_gram[3]]+=1\n",
    "                elif (n==5):\n",
    "                    ngram_counts[(n_gram[0],n_gram[1],n_gram[2],n_gram[3])][n_gram[4]]+=1\n",
    "\n",
    "    return ngram_counts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ngram where n = 2...5.\n",
    "bigram_counts=get_ngram_counts(train_set,2)\n",
    "trigram_counts=get_ngram_counts(train_set,3)\n",
    "fourgram_counts=get_ngram_counts(train_set,4)\n",
    "fivegram_counts=get_ngram_counts(train_set,5)\n",
    "\n",
    "# dictionary for query in the guesser\n",
    "ngram_counts = {1 : unigram_counts,\n",
    "           2 : bigram_counts,\n",
    "           3 : trigram_counts,\n",
    "           4 : fourgram_counts,\n",
    "           5 : fivegram_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob(letter,context,n,lambdas):\n",
    "    \n",
    "    \n",
    "    prob=0\n",
    "    \n",
    "    # create tuples to make a query with context\n",
    "    if (n>1):\n",
    "        if (len(context)>1):\n",
    "            conditional=tuple(context)\n",
    "        elif(len(context)==1):\n",
    "            conditional=context[0]\n",
    "        else:\n",
    "            conditional=tuple() # no context at all\n",
    "    \n",
    "            \n",
    "\n",
    "    if (n>4):\n",
    "        \n",
    "        # calculate the fivegram\n",
    "        fivegram_count=ngram_counts[5][conditional][letter]*lambdas[5]\n",
    "        fivegram_total_count=float(sum(ngram_counts[5][conditional].values()))\n",
    "        if fivegram_total_count!=0:\n",
    "            interp_prob_fivegram=fivegram_count/fivegram_total_count\n",
    "        else:\n",
    "            interp_prob_fivegram=0\n",
    "            lambdas[4]+=lambdas[5] #if count is 0 I will give the lambda weight to the next ngram\n",
    "            \n",
    "        prob+=interp_prob_fivegram\n",
    "        \n",
    "    if (n>3):\n",
    "        # calculate the fourgram\n",
    "        fourgram_count=ngram_counts[4][conditional][letter]*lambdas[4]\n",
    "        fourgram_total_count=float(sum(ngram_counts[4][conditional].values()))\n",
    "        if fourgram_total_count!=0:\n",
    "            interp_prob_fourgram=fourgram_count/fourgram_total_count\n",
    "        else:\n",
    "            interp_prob_fourgram=0\n",
    "            lambdas[3]+=lambdas[4] #if count is 0 I will give the lambda weight to the next ngram\n",
    "            \n",
    "        prob+=interp_prob_fourgram\n",
    "    \n",
    "    if (n>2):\n",
    "        # calculate the trigram\n",
    "        trigram_count=ngram_counts[3][conditional][letter]*lambdas[3]\n",
    "        trigram_total_count=float(sum(ngram_counts[3][conditional].values()))\n",
    "        if trigram_total_count!=0:\n",
    "            interp_prob_trigram=trigram_count/trigram_total_count\n",
    "        else:\n",
    "            interp_prob_trigram=0\n",
    "            lambdas[2]+=lambdas[3] #if count is 0 I will give the lambda weight to the next ngram\n",
    "        \n",
    "        prob+=interp_prob_trigram\n",
    "        \n",
    "    if (n>1):\n",
    "        # calculate the bigram\n",
    "        bigram_count=ngram_counts[2][conditional][letter]*lambdas[2]\n",
    "        bigram_total_count=float(sum(ngram_counts[2][conditional].values()))\n",
    "        if bigram_total_count!=0:\n",
    "            interp_prob_bigram=bigram_count/bigram_total_count\n",
    "        else:\n",
    "            interp_prob_bigram=0\n",
    "            lambdas[1]+=lambdas[2] #if count is 0 I will give the lambda weight to the next ngram\n",
    "        \n",
    "        prob+=interp_prob_bigram\n",
    "    \n",
    "    if (n>0):\n",
    "        unigram_count=ngram_counts[1][letter]*lambdas[1]\n",
    "        unigram_total_count=float(sum(ngram_counts[1].values()))\n",
    "        if unigram_total_count!=0:\n",
    "            interp_prob_unigram=(unigram_count)/(unigram_total_count) #Â not smoothed with laplace like the unigram model       \n",
    "        else:\n",
    "            \n",
    "            # out-of-vocabulary words = 1 / |V|\n",
    "            lambdas[0]+=lambdas[1]\n",
    "            vocab_size = len(unigram_total_count)\n",
    "            interp_prob_unigram = (1 / float(vocab_size)) * lambdas[0]\n",
    "        prob+=interp_prob_unigram\n",
    "        \n",
    "        \n",
    "    return math.log(prob)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed]\n",
    "    blank_probs={}\n",
    "    letter_probs={}\n",
    "    probs=[]\n",
    "    if kwargs.get('n'):       \n",
    "        n=kwargs.get('n')\n",
    "    else:\n",
    "        n=1\n",
    "        \n",
    "    if kwargs.get('lambdas'):       \n",
    "        lambdas=kwargs.get('lambdas')\n",
    "    else:\n",
    "        lambdas={1:1}\n",
    "    word=convert_word(mask,2)\n",
    "    letter_probs=defaultdict(float)\n",
    "    for i in range(len(word)):\n",
    "        if (word[i]==\"_\"):\n",
    "            context=[]\n",
    "            j=i-1\n",
    "            context_len=1\n",
    "            while word[j]!=\"_\" and j>=0 and context_len<n:\n",
    "                context.insert(0,word[j])\n",
    "                j-=1\n",
    "                context_len+=1\n",
    "            \n",
    "            for letter in letter_available:\n",
    "                probability=get_ngram_prob(letter,context.copy(),n,lambdas.copy())\n",
    "                letter_probs[letter]+=probability\n",
    "                \n",
    "              \n",
    "    letter_choice=max(letter_probs, key=letter_probs.get)\n",
    "    return letter_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_range=[0.98,0.95,0.8,0.5,0.25,0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.010000000000000009, 2: 0.98} Avg Mistakes: 8.783\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.040000000000000036, 2: 0.95} Avg Mistakes: 8.828\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.18999999999999995, 2: 0.8} Avg Mistakes: 9.018\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.49, 2: 0.5} Avg Mistakes: 9.476\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.74, 2: 0.25} Avg Mistakes: 9.949\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.989, 2: 0.001} Avg Mistakes: 10.719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for bigram_lambda in lambdas_range:\n",
    "    zerogram_lambda=0.01\n",
    "    unigram_lambda = 1- zerogram_lambda - bigram_lambda\n",
    "    lambdas_bigram = {0:zerogram_lambda,\n",
    "           1 : unigram_lambda,\n",
    "           2 : bigram_lambda\n",
    "    }\n",
    "    \n",
    "    print('Lambdas (Sum='+str(sum(lambdas_bigram.values()))+'):',lambdas_bigram,'Avg Mistakes:',evaluate_model(ngram_guesser,test_set,n=2, lambdas=lambdas_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.00156637158891027, 2: 0.008433628411089748, 3: 0.98} Avg Mistakes: 8.74\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.0014643439003896534, 2: 0.03853565609961039, 3: 0.95} Avg Mistakes: 8.758\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.0012604792228405413, 2: 0.18873952077715941, 3: 0.8} Avg Mistakes: 8.836\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.08731855318421734, 2: 0.40268144681578266, 3: 0.5} Avg Mistakes: 9.146\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.04754127009828391, 2: 0.6924587299017161, 3: 0.25} Avg Mistakes: 9.48\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.08243640015949828, 2: 0.9065635998405017, 3: 0.001} Avg Mistakes: 10.353\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for trigram_lambda in lambdas_range:\n",
    "    zerogram_lambda=0.01\n",
    "    bigram_lambda = random.uniform(0.8, 1)*(1-zerogram_lambda-trigram_lambda)\n",
    "    unigram_lambda=1-trigram_lambda-bigram_lambda-zerogram_lambda\n",
    "    lambdas_trigram = {0:zerogram_lambda,\n",
    "           1 : unigram_lambda,\n",
    "           2 : bigram_lambda,\n",
    "            3: trigram_lambda\n",
    "    }\n",
    "    print('Lambdas (Sum='+str(sum(lambdas_trigram.values()))+'):',lambdas_trigram,'Avg Mistakes:',evaluate_model(ngram_guesser,test_set,n=3, lambdas=lambdas_trigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.0009222287952319712, 2: 0.007705275923174914, 3: 0.0013724952815931336, 4: 0.98} Avg Mistakes: 8.831\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.008837736303773177, 2: 0.0007930191877357932, 3: 0.030369244508491072, 4: 0.95} Avg Mistakes: 8.845\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.038698147023799, 2: 0.09542031171547886, 3: 0.05588154126072208, 4: 0.8} Avg Mistakes: 8.857\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.25595042574021354, 2: 0.1321738511705646, 3: 0.10187572308922185, 4: 0.5} Avg Mistakes: 9.076\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.15566851954323147, 2: 0.007145582416609344, 3: 0.5771858980401592, 4: 0.25} Avg Mistakes: 9.272\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.22209746238399786, 2: 0.7329895426513903, 3: 0.03391299496461189, 4: 0.001} Avg Mistakes: 10.373\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for fourgram_lambda in lambdas_range:\n",
    "    zerogram_lambda=0.01\n",
    "    trigram_lambda=random.uniform(0, 1)*(1-zerogram_lambda-fourgram_lambda)\n",
    "    bigram_lambda = random.uniform(0, 1)*(1-zerogram_lambda-fourgram_lambda-trigram_lambda)\n",
    "    unigram_lambda=1-fourgram_lambda-trigram_lambda-bigram_lambda-zerogram_lambda\n",
    "    lambdas_fourgram = {0:zerogram_lambda,\n",
    "        1 : unigram_lambda,\n",
    "        2 : bigram_lambda,\n",
    "        3 : trigram_lambda,\n",
    "        4 : fourgram_lambda\n",
    "    }\n",
    "    print('Lambdas (Sum='+str(sum(lambdas_fourgram.values()))+'):',lambdas_fourgram,'Avg Mistakes:',evaluate_model(ngram_guesser,test_set,n=4, lambdas=lambdas_fourgram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.0012130405635881018, 2: 0.0057118991780785704, 3: 0.000931490429769466, 4: 0.0021435698285638778, 5: 0.98} Avg Mistakes: 9.313\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.0003260938048536468, 2: 0.002436892640600408, 3: 0.009257147987483788, 4: 0.027979865567062202, 5: 0.95} Avg Mistakes: 9.314\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.012058112051390261, 2: 0.013026680483510241, 3: 0.06589560494357394, 4: 0.09901960252152552, 5: 0.8} Avg Mistakes: 9.294\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.02670378183883581, 2: 0.02643966681837347, 3: 0.369402593708379, 4: 0.06745395763441168, 5: 0.5} Avg Mistakes: 9.328\n",
      "Lambdas (Sum=1.0): {0: 0.01, 1: 0.04082198138445369, 2: 0.0006568775816813249, 3: 0.3265139605867537, 4: 0.3720071804471113, 5: 0.25} Avg Mistakes: 9.386\n",
      "Lambdas (Sum=0.9999999999999999): {0: 0.01, 1: 0.3790804804892498, 2: 0.17615481637541833, 3: 0.0953211335136957, 4: 0.3384435696216362, 5: 0.001} Avg Mistakes: 10.281\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for fivegram_lambda in lambdas_range:\n",
    "    zerogram_lambda=0.01\n",
    "    fourgram_lambda=random.uniform(0, 1)*(1-zerogram_lambda-fivegram_lambda)\n",
    "    trigram_lambda=random.uniform(0, 1)*(1-zerogram_lambda-fivegram_lambda-fourgram_lambda)\n",
    "    bigram_lambda = random.uniform(0, 1)*(1-zerogram_lambda-fivegram_lambda-fourgram_lambda-trigram_lambda)\n",
    "    unigram_lambda=1-fivegram_lambda-fourgram_lambda-trigram_lambda-bigram_lambda-zerogram_lambda\n",
    "    lambdas_fivegram = {0:zerogram_lambda,\n",
    "        1 : unigram_lambda,\n",
    "        2 : bigram_lambda,\n",
    "        3 : trigram_lambda,\n",
    "        4 : fourgram_lambda,\n",
    "        5 : fivegram_lambda\n",
    "    }\n",
    "    print('Lambdas (Sum='+str(sum(lambdas_fivegram.values()))+'):',lambdas_fivegram,'Avg Mistakes:',evaluate_model(ngram_guesser,test_set,n=5, lambdas=lambdas_fivegram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant improvement. The trigram is apparently the best model according to results. Additionally, the lambda values for smoothing seems to perform better when the weight is in favor for the highest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
