{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use two datasets for training: 1) the Penn Treebank sample used in the workshops and 2) the Twitter samples from NLTK. In order to adapt the tagger to the Twitter data we need to built a *joint* vocabulary containing all the word types in PTB and the twitter_samples corpora. So, in addition to preprocessing, I will build this vocabulary. \n",
    "\n",
    "The vocabulary and the tagset should be stored in Python dictionaries, mapping each word (or tag) to an index (integer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence - Treebank: [(0, 0), (1, 0), (2, 1), (3, 2), (4, 3), (5, 4), (2, 1), (6, 5), (7, 6), (8, 7), (9, 8), (10, 9), (11, 7), (12, 4), (13, 8), (14, 0), (15, 2), (16, 10)]\n",
      "Index of word electricity: 1095\n",
      "Tagset size: 46\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from collections import defaultdict\n",
    "\n",
    "## PTB\n",
    "\n",
    "\n",
    "corpus = treebank.tagged_sents()\n",
    "\n",
    "word_numbers = {} # vocabulary\n",
    "tag_numbers = {} # tagset\n",
    "\n",
    "training_ptb_corpus = []\n",
    "for sent in corpus:\n",
    "    num_sent = []\n",
    "    for word, tag in sent: # iterate over the sentences in corpus to get tuples (word,tag)\n",
    "        wi = word_numbers.setdefault(word.lower(), len(word_numbers))\n",
    "        ti = tag_numbers.setdefault(tag, len(tag_numbers))\n",
    "        num_sent.append((wi, ti)) # tuple word, tag\n",
    "    training_ptb_corpus.append(num_sent) # generate the pre processed corpus\n",
    "    \n",
    "\n",
    "    \n",
    "S = len(tag_numbers)\n",
    "V = len(word_numbers)\n",
    "    \n",
    "print(\"First sentence - Treebank:\",training_ptb_corpus[0])\n",
    "print(\"Index of word electricity:\",word_numbers['electricity'])\n",
    "print(\"Tagset size:\",S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for twitter_samples dataset (**training** tweets), since this data is not tagged, the preprocessed corpus will be a list where each element is another list containing indices only (instead of (word, tag) tuples).\n",
    "\n",
    "There are two things to keep in mind when doing this process:\n",
    "\n",
    "1) We will perform a bit more of preprocessing in this dataset, besides lowercasing. Specifically, I will replace special tokens with special symbols, as follows:\n",
    "- Username mentions are tokens that start with '@': replace these tokens with 'USER_TOKEN'\n",
    "- Hashtags are tokens that start with '#': replace these with 'HASHTAG_TOKEN'\n",
    "- Retweets are represented as the token 'RT' (or 'rt' if you lowercase first): replace these with 'RETWEET_TOKEN'\n",
    "- URLs are tokens that start with 'https://' or 'http://': replace these with 'URL_TOKEN'\n",
    "\n",
    "2) update the vocabulary built from PTB with any new words present in this corpus. These will *include* the special tokens defined above but *not* the original un-preprocessed tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence training tweets indexes: [11387, 182, 11388, 11389]\n",
      "Index of word electricity: 1095\n",
      "Index of word HASHTAG_TOKEN: 11409\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "corpus_twitter=twitter_samples.tokenized()\n",
    "\n",
    "def preprocess_word(word):\n",
    "    word=word.lower()\n",
    "    if (word.startswith('#')):\n",
    "        word='HASHTAG_TOKEN'\n",
    "    elif (word.startswith('@')):\n",
    "        word='USER_TOKEN'\n",
    "    elif (word==\"rt\"):\n",
    "        word='RETWEET_TOKEN'\n",
    "    elif (word.startswith(\"http://\") or (word.startswith(\"https://\"))):\n",
    "        word='URL_TOKEN'\n",
    "        \n",
    "    return word\n",
    "\n",
    "\n",
    "\n",
    "training_tweets_corpus=[]\n",
    "\n",
    "# preprocess the words with twitter tokens\n",
    "for tweet in corpus_twitter:\n",
    "    for word in tweet:\n",
    "        word_preprocessed=preprocess_word(word)\n",
    "        word_numbers.setdefault(word_preprocessed,len(word_numbers))\n",
    "\n",
    "# create the training twitter dataset\n",
    "for tweet in corpus_twitter:\n",
    "    num_tweet = []\n",
    "    for word in tweet:\n",
    "        num_tweet.append(word_numbers.get(word))\n",
    "    training_tweets_corpus.append(num_tweet) \n",
    "\n",
    "\n",
    "\n",
    "V = len(word_numbers)\n",
    "    \n",
    "print(\"First sentence training tweets indexes:\", training_tweets_corpus[0])\n",
    "print(\"Index of word electricity:\", word_numbers['electricity'])\n",
    "print(\"Index of word HASHTAG_TOKEN:\",word_numbers['HASHTAG_TOKEN'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will preprocess the tagged twitter corpus (Ritter et al.) and update the tagset. This dataset will be referred from now on as **test** tweets.\n",
    "\n",
    "This dataset has a few extra tags, besides the PTB ones. These were added to incorporate specific phenomena that happens on Twitter:\n",
    "- \"USR\": username mentions\n",
    "- \"HT\": hashtags\n",
    "- \"RT\": retweets\n",
    "- \"URL\": URL addresses\n",
    "\n",
    "There a few additional tags which are not specific to Twitter but are not present in the PTB sample:\n",
    "- \"VPP\"\n",
    "- \"TD\"\n",
    "- \"O\"\n",
    "\n",
    "I willadd these new seven tags to the tagset built when reading the PTB corpus.\n",
    "\n",
    "I will also add an extra type to the vocabulary: `<unk>`. This is in order to account for unknown or out-of-vocabulary words.\n",
    "\n",
    "Finally, build two \"inverted indices\" for the vocabulary and the tagset. These should be lists, where the \"i\"-th element should contain the word (or tag) corresponding to the index \"i\" in the vocabulary (or tagset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of word <unk>: 26069\n",
      "New Tagset size: 53\n"
     ]
    }
   ],
   "source": [
    "# update the tagset with 7 extra tags\n",
    "ti = tag_numbers.setdefault(\"USR\", len(tag_numbers))\n",
    "ti = tag_numbers.setdefault(\"HT\", len(tag_numbers))\n",
    "ti = tag_numbers.setdefault(\"RT\", len(tag_numbers))\n",
    "ti = tag_numbers.setdefault(\"URL\", len(tag_numbers))\n",
    "ti = tag_numbers.setdefault(\"VPP\", len(tag_numbers))\n",
    "ti = tag_numbers.setdefault(\"TD\", len(tag_numbers))\n",
    "ti = tag_numbers.setdefault(\"O\", len(tag_numbers))\n",
    "\n",
    "S = len(tag_numbers)\n",
    "\n",
    "#Another task is to add an extra type to the vocabulary: <unk>\n",
    "word_numbers.setdefault(\"<unk>\",len(word_numbers))\n",
    "\n",
    "# create inverted lists\n",
    "def get_vocabulary_list():\n",
    "    word_names = [None] * len(word_numbers)\n",
    "    for word, index in word_numbers.items():\n",
    "        word_names[index] = word\n",
    "    return word_names\n",
    "\n",
    "def get_tagset_list():\n",
    "    tag_names = [None] * len(tag_numbers)\n",
    "    for tag, index in tag_numbers.items():\n",
    "        tag_names[index] = tag\n",
    "    return tag_names\n",
    "\n",
    "word_names=get_vocabulary_list()\n",
    "tag_names=get_tagset_list()\n",
    "\n",
    "print(\"Index of word <unk>:\", word_numbers['<unk>'])\n",
    "print(\"New Tagset size:\",S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the test tweets, store them in the same format as the PTB corpora (list of lists containing (word, tag) index tuples). However, **I will not** update the vocabulary. Why? Because the test set should simulate a real-world scenario, where out-of-vocabulary words can appear. Instead, after preprocessing each word, I will check if that word is in the vocabulary. If yes, just replace it with its index, otherwise I replace it with the index for the `<unk>` token. \n",
    "\n",
    "I will also do a mapping for the PTB POS tags:\n",
    "- \"(\". In PTB, this is represented as \"-LRB-\"\n",
    "- \")\". In PTB, this is represented as \"-RRB-\"\n",
    "- \"NONE\". In PTB, this is represented as \"-NONE-\"\n",
    "\n",
    "As I build the corpus for the test tweets, you will check if the tag for a word is one of the above. If yes, I will use the PTB equivalent instead. In practice, it is sufficient to ensure you use the correct index for the corresponding tag, using your tagset dictionary. This concept is sometimes referred as *tag harmonisation*, where two different tagsets are mapped to each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11392, 46), (61, 19), (114, 11), (8, 7), (3224, 8), (170, 9), (325, 33), (1325, 19), (2375, 22), (3205, 12), (182, 9), (799, 2), (1522, 3), (16, 10), (8490, 0), (1146, 0), (2495, 0), (14039, 43), (26069, 0), (16, 10), (4263, 17), (1760, 4), (9464, 8), (2259, 17), (888, 4), (741, 8), (16, 10)]\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "try:\n",
    "    urllib.request.urlretrieve(\"https://github.com/aritter/twitter_nlp/raw/master/data/annotated/pos.txt\",\"pos.txt\")\n",
    "except: # Python 2\n",
    "    urllib.urlretrieve(\"https://github.com/aritter/twitter_nlp/raw/master/data/annotated/pos.txt\",\"pos.txt\")\n",
    "\n",
    "\n",
    "test_inputs = []\n",
    "words_pos = []\n",
    "with open('pos.txt') as f:\n",
    "    words = []\n",
    "    pos_tags = []\n",
    "    for line in f:\n",
    "        if line.strip() == '':\n",
    "            #num_corpus.append(num_sent)\n",
    "            test_inputs.append(words_pos)\n",
    "            words_pos = []\n",
    "        else:\n",
    "            word, pos = line.strip().split()\n",
    "            word=preprocess_word(word) # pre process the word according to what we are expecting\n",
    "            \n",
    "            # preprocess unknown words\n",
    "            if word_numbers.get(word):\n",
    "                wi=word_numbers[word]\n",
    "            else:\n",
    "                wi=word_numbers['<unk>']\n",
    "            \n",
    "            # preprocess tags\n",
    "            if pos == \"(\":\n",
    "                pos=\"-LRB-\"\n",
    "            if pos == \")\":\n",
    "                pos=\"-RRB-\"\n",
    "            if pos == \"NONE\":\n",
    "                pos=\"-NONE-\"\n",
    "                \n",
    "            ti = tag_numbers[pos]\n",
    "            \n",
    "            words_pos.append((wi, ti))\n",
    "    \n",
    "    \n",
    "print (test_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26070\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(word_numbers))\n",
    "print(len(tag_numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Running the PTB tagger on the test tweets (1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train a POS tagger on the PTB data and try it on the test tweets. \n",
    "\n",
    "The first task is use HMM (Hidden Markov Model) and obtain for training:\n",
    "- The initial tag probabilities (a vector).\n",
    "- The transition probabilities (a matrix).\n",
    "- The emission probabilities (a matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def count(tagged_corpus,vocabulary,tagset):\n",
    "    \n",
    "    S=len(tagset)\n",
    "    V=len(vocabulary)\n",
    "    \n",
    "    # initalise\n",
    "    eps = 0.1\n",
    "    pi = eps * np.ones(S) # initial tag probability\n",
    "    A = eps * np.ones((S, S)) # transition probability\n",
    "    O = eps * np.ones((S, V)) # emission probability\n",
    "\n",
    "    # count\n",
    "    for sent in tagged_corpus:\n",
    "        last_tag = None\n",
    "        for word, tag in sent:\n",
    "            O[tag, word] += 1 # counting for emission probabilities\n",
    "            if last_tag == None:\n",
    "                pi[tag] += 1\n",
    "            else:\n",
    "                A[last_tag, tag] += 1 # counting for transition probabilities\n",
    "            last_tag = tag\n",
    "\n",
    "    # normalise\n",
    "    pi /= np.sum(pi)\n",
    "    for s in range(S):\n",
    "        O[s,:] /= np.sum(O[s,:])\n",
    "        A[s,:] /= np.sum(A[s,:])\n",
    "\n",
    " \n",
    "    return pi,A,O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_ptb_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29836fb80ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get the initial, transition and emision matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_ptb_corpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_numbers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_ptb_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# get the initial, transition and emision matrix\n",
    "pi, A, O= count(training_ptb_corpus,word_numbers,tag_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will define a function for Viterbi Algorithm taking as input:\n",
    "- The parameters (probabilities) of HMM (a tuple (initial, transition, emission)).\n",
    "- The input words (a list with numbers).\n",
    "\n",
    "And getting as the output:\n",
    "- A list of (word, tag) indices, containing the original input word and the predicted tag.\n",
    "\n",
    "I will run Viterbi on the test tweets and store the predictions in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(params, observations):\n",
    "        pi, A, O = params # where pi is the initial tag probability, A is the transition matrix and O the emission matrix\n",
    "        M = len(observations)\n",
    "        S = pi.shape[0]\n",
    "\n",
    "        alpha = np.zeros((M, S))\n",
    "        alpha[:,:] = float('-inf')\n",
    "        backpointers = np.zeros((M, S), 'int')\n",
    "\n",
    "        # base case\n",
    "        alpha[0, :] = pi * O[:,observations[0]]\n",
    "\n",
    "        # recursive case\n",
    "        for t in range(1, M):\n",
    "            for s2 in range(S):\n",
    "                for s1 in range(S):\n",
    "                    score = alpha[t-1, s1] * A[s1, s2] * O[s2, observations[t]]\n",
    "                    if score > alpha[t, s2]:\n",
    "                        alpha[t, s2] = score\n",
    "                        backpointers[t, s2] = s1\n",
    "\n",
    "        # now follow backpointers to resolve the state sequence\n",
    "        ss = []\n",
    "        ss.append(np.argmax(alpha[M-1,:]))\n",
    "        for i in range(M-1, 0, -1):\n",
    "            ss.append(backpointers[i, ss[-1]])\n",
    "            \n",
    "        predictions=list(reversed(ss))\n",
    "        observation_predicted_tag=[]\n",
    "        \n",
    "        # create the output of model prediction\n",
    "        for index in range(M):\n",
    "            observation_predicted_tag.append((observations[index],predictions[index]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return observation_predicted_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11392, 27), (61, 19), (114, 11), (8, 7), (3224, 8), (170, 9), (325, 33), (1325, 19), (2375, 22), (3205, 12), (182, 9), (799, 2), (1522, 3), (16, 10), (8490, 29), (1146, 8), (2495, 8), (14039, 10), (26069, 38), (16, 10), (4263, 29), (1760, 4), (9464, 8), (2259, 17), (888, 4), (741, 8), (16, 10)]\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "predictions = []\n",
    "for sent in test_inputs:\n",
    "    encoded_sent = [word[0] for word in sent] # get the word indexes for each word\n",
    "    predictions.append(viterbi((pi, A, O), encoded_sent))\n",
    "\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results I will use a function that takes (word, tag) lists as inputs and outputs the tag sequence using the original tags in the tagset. Inputs will be a sentence and the tag inverted index I built before.\n",
    "\n",
    "I run this function on the predictions  obtained above and the test tweets, storing them in two separate lists. Finally, I will put predictions into a single list and do the same for the test tweets reporting accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637141916365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "#input_word_tag is a sentence with predicted tag\n",
    "def get_tag_sequence(input_word_tag):\n",
    "    tag_secuence=[]\n",
    "    for word_tag in input_word_tag:\n",
    "        tag_secuence.append(tag_names[word_tag[1]])\n",
    "    \n",
    "    # output the tag sequence using original tags in the tagset\n",
    "    return tag_secuence\n",
    "\n",
    "predicted_tag_sequence=[]\n",
    "for pred in predictions:\n",
    "    predicted_tag_sequence.append(get_tag_sequence(pred))\n",
    "\n",
    "original_tag_sequence=[]\n",
    "for sent in test_inputs:\n",
    "    original_tag_sequence.append([tag_names[word[1]] for word in sent] )\n",
    "\n",
    "# flat our data into single lists\n",
    "all_test_tags = [tag for tags in original_tag_sequence for tag in tags]\n",
    "# for predictions, we need to obtain the original tag from the index\n",
    "all_pred_tags = [tag for tags in predicted_tag_sequence for tag in tags]\n",
    "\n",
    "print (acc(all_test_tags, all_pred_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Adapting the tagger using prior information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will adapt the tagger using prior information. What do we mean by that? Remember from part 1 that the twitter tagset has some extra tags, related to special tokens such as mentions and hashtags. In other words, **we know beforehand** that these special tokens **should** have these tags. However, because these tags never appear in the PTB data, the tagger has no such information. We are going to add this in order to improve the tagger.\n",
    "\n",
    "To recap, we know these things about the twitter data:\n",
    "- username mentions should have the tag 'USR'\n",
    "- hashtags should have the tag 'HT'\n",
    "- retweet tokens should have the tag 'RT'\n",
    "- URL tokens should have the tag 'URL'\n",
    "\n",
    "Remember how I replace these tokens with unique special ones (such as 'USER_TOKEN')? The task is to adapt the emission probabilities for these tokens. Modifying the emission matrix: assign 1.0 probability for the emission P('USER_TOKEN'|'USR') and 0.0 for P(word|'USR') for all other words. (The same for the other three special tags).\n",
    "\n",
    "In order to do that, I use the vocabulary and tagset dictionaries in order to obtain the indices for the corresponding words and tags. Then, use the indices to find the values in the emission matrix and modify them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_2(tagged_corpus,vocabulary,tagset):\n",
    "    \n",
    "    S=len(tagset)\n",
    "    V=len(vocabulary)\n",
    "    \n",
    "    \n",
    "    # initalise\n",
    "    eps = 0.1\n",
    "    pi = eps * np.ones(S) # initial tag probability\n",
    "    A = eps * np.ones((S, S)) # transition probability\n",
    "    O = eps * np.ones((S, V)) # emission probability\n",
    "\n",
    "    # count\n",
    "    for sent in tagged_corpus:\n",
    "        last_tag = None\n",
    "        for word, tag in sent:\n",
    "            O[tag, word] += 1 # counting for emission probabilities\n",
    "            if last_tag == None:\n",
    "                pi[tag] += 1\n",
    "            else:\n",
    "                A[last_tag, tag] += 1 # counting for transition probabilities\n",
    "            last_tag = tag\n",
    "\n",
    "    # normalise\n",
    "    pi /= np.sum(pi)\n",
    "    for s in range(S):\n",
    "        O[s,:] /= np.sum(O[s,:])\n",
    "        A[s,:] /= np.sum(A[s,:])\n",
    "        \n",
    "\n",
    "    # adjust the probabilities for special tokens\n",
    "    # set everything to 0\n",
    "    O[tag_numbers['USR']][:]=0.0\n",
    "    O[tag_numbers['HT']][:]=0.0\n",
    "    O[tag_numbers['RT']][:]=0.0\n",
    "    O[tag_numbers['URL']][:]=0.0\n",
    "    O[tag_numbers['USR']][word_numbers['USER_TOKEN']]=1.0\n",
    "    O[tag_numbers['HT']][word_numbers['HASHTAG_TOKEN']]=1.0\n",
    "    O[tag_numbers['RT']][word_numbers['RETWEET_TOKEN']]=1.0\n",
    "    O[tag_numbers['URL']][word_numbers['URL_TOKEN']]=1.0\n",
    "    \n",
    "  \n",
    "    return pi,A,O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.15369893e-05   1.74752434e-04   8.32154448e-06 ...,   8.32154448e-06\n",
      "    8.32154448e-06   8.32154448e-06]\n",
      " [  1.33457894e-05   1.33457894e-05   6.51955158e-01 ...,   1.33457894e-05\n",
      "    1.33457894e-05   1.33457894e-05]\n",
      " [  1.62522347e-05   1.62522347e-05   1.62522347e-05 ...,   1.62522347e-05\n",
      "    1.62522347e-05   1.62522347e-05]\n",
      " ..., \n",
      " [  3.83582662e-05   3.83582662e-05   3.83582662e-05 ...,   3.83582662e-05\n",
      "    3.83582662e-05   3.83582662e-05]\n",
      " [  3.83582662e-05   3.83582662e-05   3.83582662e-05 ...,   3.83582662e-05\n",
      "    3.83582662e-05   3.83582662e-05]\n",
      " [  3.83582662e-05   3.83582662e-05   3.83582662e-05 ...,   3.83582662e-05\n",
      "    3.83582662e-05   3.83582662e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I evaluate the new tagger on the test tweets again and report accuracy using a fine-grained error analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695093842608\n"
     ]
    }
   ],
   "source": [
    "word_names=get_vocabulary_list()\n",
    "tag_names=get_tagset_list()\n",
    "pi, A, O= count_2(training_ptb_corpus,word_numbers,tag_numbers)\n",
    "predictions = []\n",
    "for sent in test_inputs:\n",
    "    encoded_sent = [word[0] for word in sent] # get the word indexes for each word\n",
    "    predictions.append(viterbi((pi, A, O), encoded_sent))\n",
    "\n",
    "predicted_tag_sequence=[]\n",
    "for pred in predictions:\n",
    "    predicted_tag_sequence.append(get_tag_sequence(pred))\n",
    "\n",
    "original_tag_sequence=[]\n",
    "for sent in test_inputs:\n",
    "    original_tag_sequence.append([tag_names[word[1]] for word in sent] )\n",
    "\n",
    "# flat our data into single lists\n",
    "all_test_tags = [tag for tags in original_tag_sequence for tag in tags]\n",
    "# for predictions, we need to obtain the original tag from the index\n",
    "all_pred_tags = [tag for tags in predicted_tag_sequence for tag in tags]\n",
    "\n",
    "print (acc(all_test_tags, all_pred_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.695093842608\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          #       0.00      0.00      0.00         0\n",
      "          $       0.00      0.00      0.00         0\n",
      "         ''       0.03      0.20      0.06        91\n",
      "          ,       0.85      1.00      0.92       303\n",
      "      -LRB-       0.00      0.00      0.00        32\n",
      "     -NONE-       0.00      0.00      0.00         2\n",
      "      -RRB-       0.04      0.15      0.07        34\n",
      "          .       0.72      0.83      0.77       875\n",
      "          :       0.97      0.76      0.85       562\n",
      "         CC       0.96      0.88      0.92       305\n",
      "         CD       0.59      0.59      0.59       268\n",
      "         DT       0.74      0.93      0.82       825\n",
      "         EX       0.38      0.80      0.52        10\n",
      "         FW       0.00      0.00      0.00         3\n",
      "         HT       0.98      0.98      0.98       135\n",
      "         IN       0.81      0.88      0.85      1091\n",
      "         JJ       0.64      0.59      0.61       670\n",
      "        JJR       0.48      0.74      0.58        31\n",
      "        JJS       0.84      0.81      0.82        26\n",
      "         LS       0.00      0.00      0.00         1\n",
      "         MD       0.53      0.97      0.69       181\n",
      "         NN       0.79      0.63      0.70      1931\n",
      "        NNP       0.60      0.27      0.37      1159\n",
      "       NNPS       0.00      0.00      0.00         8\n",
      "        NNS       0.43      0.54      0.48       393\n",
      "          O       0.00      0.00      0.00         1\n",
      "        PDT       0.00      0.00      0.00         1\n",
      "        POS       0.39      0.78      0.52        36\n",
      "        PRP       0.86      0.82      0.84      1106\n",
      "       PRP$       0.84      0.86      0.85       234\n",
      "         RB       0.71      0.76      0.73       680\n",
      "        RBR       0.62      0.25      0.36        20\n",
      "        RBS       0.08      0.33      0.12         3\n",
      "         RP       0.64      0.45      0.53       110\n",
      "         RT       1.00      1.00      1.00       152\n",
      "        SYM       0.00      0.00      0.00        13\n",
      "         TD       0.00      0.00      0.00         1\n",
      "         TO       0.84      0.96      0.90       264\n",
      "         UH       1.00      0.00      0.00       493\n",
      "        URL       0.99      0.90      0.95       183\n",
      "        USR       0.98      0.96      0.97       464\n",
      "         VB       0.65      0.70      0.68       660\n",
      "        VBD       0.77      0.74      0.75       306\n",
      "        VBG       0.88      0.50      0.64       303\n",
      "        VBN       0.43      0.63      0.51       140\n",
      "        VBP       0.78      0.64      0.70       527\n",
      "        VBZ       0.69      0.78      0.73       342\n",
      "        VPP       0.00      0.00      0.00         1\n",
      "        WDT       0.36      0.47      0.41        19\n",
      "         WP       0.97      0.74      0.84        47\n",
      "        WP$       0.00      0.00      0.00         0\n",
      "        WRB       1.00      0.81      0.90       143\n",
      "         ``       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.76      0.70      0.70     15185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def print_report(predictions, classifications):\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy_score(classifications,predictions))\n",
    "    print(classification_report(classifications,predictions))\n",
    "    \n",
    "print_report(all_pred_tags,all_test_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the tags predicted as the tag in analysis, the precision give us an idea how many of them were actually that specific tag. I can see several situations where this prediction was really low.\n",
    "Aditionally, of the tags that were actually the tag in analysis, the proportion of the tags that were classified as this tag specifically doesn't meet the expectations.\n",
    "Moreover, we can see a few tags we don't have True Positives and False Positives or False Negatives. For that reason our Precision, Recall or F-Measure is indefinied (support 0).\n",
    "\n",
    "In the first tasks, we created the tagset according to twitter, but then, we trained the model with PTB corpus and tested it with twitter data. If we can train the model with with twitter data we can probably increase the performance, as the writing styles from PTB and Twitter corpus are significantly different. \n",
    "\n",
    "As a consequence, if we take a look at some tags with a large support, we can find some of them with low performance:\n",
    "- CD : Cardinal Number\n",
    "- JJ: Adjectives\n",
    "- IN: Prepositions - Could be improved\n",
    "- NN*: For some of them we have significant good support, however, our scores are in general low.\n",
    "- VBN, VBG: Verbs conjucations have a low score and could be improved.\n",
    "\n",
    "There are general observations for other tags/words that can be improved:\n",
    "- Punctuation symbols.\n",
    "- Include emoticons in the model since are very popular on twitter.\n",
    "- mix of symbols + words + numbers may be confusing, we should preprocess this words.\n",
    "\n",
    "Finally, a combination with other technique like using bgrams or modifications to the classifier could help to improve the score too as we can have more context to train the model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
